{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/CNN-Architectures/blob/master/plant2022_part1_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plant Classification\n",
        "\n",
        "### [Link of  code ](https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/notebook).\n",
        "\n",
        "### Data : 2022-2-8 \n",
        "\n"
      ],
      "metadata": {
        "id": "_p80bZYZFzv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5IOzd5LAjSHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYgMakV4BeTh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "import cv2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "# from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# folder path\n",
        "dir_path = r'/content/drive/MyDrive/data/data/Tomato Healthy'\n",
        "count = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(dir_path):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(dir_path, path)):\n",
        "        count += 1\n",
        "print('File count:', count)"
      ],
      "metadata": {
        "id": "PrvS1XuiCnkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data  to train ,  validation and test\n",
        "# ! pip install split_folders\n",
        "# import splitfolders \n",
        "# Home = '/content/drive/MyDrive/data/data'\n",
        "# Aftersplit='/content/drive/MyDrive/split_data'\n",
        "# splitfolders.ratio(Home, Aftersplit, seed=1337, ratio=(.8, 0.2))"
      ],
      "metadata": {
        "id": "jaZZ_UCJjiMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 25\n",
        "INIT_LR = 1e-3\n",
        "BS = 60\n",
        "default_image_size = tuple((256, 256))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/MyDrive/data'\n",
        "width=256\n",
        "height=256\n",
        "depth=3"
      ],
      "metadata": {
        "id": "nkC5Dw7OB_rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "TjZ-aWTjDN6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:600]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "metadata": {
        "id": "AbEtZYlZDVXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "metadata": {
        "id": "lqsG-5SoDbX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "metadata": {
        "id": "sneP861gDbid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "metadata": {
        "id": "xmYLaGOKFBa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "metadata": {
        "id": "NhrFFXUcFFKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_data, y_train, y_data = train_test_split(np_image_list, image_labels, test_size=0.3, random_state = 42) \n",
        "x_val, x_test, y_val, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state = 42) "
      ],
      "metadata": {
        "id": "8nh4mqO_FJSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_val)"
      ],
      "metadata": {
        "id": "UQF9ER77v_ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, # rotation      \n",
        "        zoom_range=[0.5,1], # zoom\n",
        "\t\t\t\tshear_range=.2 ,\n",
        "        horizontal_flip=True, # horizontal flip\n",
        "\t\t\t\tfill_mode='nearest')"
      ],
      "metadata": {
        "id": "ftPYnvjZFL8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D"
      ],
      "metadata": {
        "id": "TPz360M4IM-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()   \n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1  \n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", name=\"Conv2D\"   ,  strides=(2,2)  ,   input_shape=inputShape))  # here  CL first layer in CNN\n",
        "model.add(Activation(\"relu\")) # here\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3),    name=\"MaxPooling2D\")   )   # here   maMaxPooling    2 layer in CNN \n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3) ,  strides=(2,2), name=\"Conv2D1\"  ))  # here\n",
        "model.add(Activation(\"relu\")) # here\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding =\"same\"  ,  strides=(2,2), name=\"Conv2D3\"   )) # here\n",
        "model.add(Activation(\"relu\")) # here\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)  , name=\"MaxPooling2D2\" ) ) # here\n",
        "model.add(Dropout(0.25))  # To avoid the overfit problem by hide .25 from nuron in network \n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\" ,  strides=(2,2), name=\"Conv2D4\"   ))  # here\n",
        "model.add(Activation(\"relu\"))  # here\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"   ,   strides=(2,2), name=\"Conv2D5\"   )) # here\n",
        "model.add(Activation(\"relu\")) # here\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)  ,    name=\"MaxPooling2D3\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))  # 1024 nuron of all network \n",
        "model.add(Activation(\"relu\"))  # here  Activation Function \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))    # Last layer for  Classification Depend on Number of class  8 classes\n",
        "model.add(Activation(\"softmax\")) #  softmax  for Multi Classification  , Sigmond For Binary Classification \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, mode=\"auto\")"
      ],
      "metadata": {
        "id": "XjfMGISYFMJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "h-Tk5StEFaD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "metadata": {
        "id": "zvhdu4_aFbuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_val, y_val),\n",
        "    steps_per_epoch=len(x_train) // BS, \n",
        "    epochs=46, verbose=1 ,  callbacks=[early_stopping] )"
      ],
      "metadata": {
        "id": "lOtb8V-BFbwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test)"
      ],
      "metadata": {
        "id": "MvV91--4x6Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "u7W335GWyQ7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'ro', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'co', label='validation  accuracy')\n",
        "plt.title('Training and validation  accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'yo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='validation  loss')\n",
        "plt.title('Training and validation  loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "92Az0dnkhl_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and Test accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Test accurarcy')\n",
        "plt.title('Training and Test accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and Test loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Test loss')\n",
        "plt.title('Training and Test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "twKF-LtUFbzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "bEZ03qnFFsqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kr_88ENhwdzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train = model.predict(x_train)\n",
        "pred_test = model.predict(x_test)  "
      ],
      "metadata": {
        "id": "xskxTnF8zu2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Train Accuracy = ',accuracy_score(y_train,pred_train.round()))\n",
        "print('Test Accuracy = ',accuracy_score(y_test,pred_test.round()))"
      ],
      "metadata": {
        "id": "8N5SvOcC2QO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test=np.argmax(pred_test, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "cm = confusion_matrix(y_test, pred_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "zTmKPCBz4fmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = model.predict(x_test)\n",
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "predicted_classes.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "ZQaiiKRP0Qus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.where(predicted_classes==y_test)[0]\n",
        "print(\"Found %d correct labels\" % len(correct))\n",
        "for i, correct in enumerate(correct[:8]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "mXUyoNRN0kwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(n_classes)]\n",
        "print(classification_report(y_test, predicted_classes, target_names=target_names))"
      ],
      "metadata": {
        "id": "5fLky2TP1PJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "\n",
        "ax = sns.heatmap(cm, annot=True, cmap='winter' , linewidths=.9)\n",
        "\n",
        "ax.set_title('The Heatmap\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Cabbage  mildew' , 'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " ' Cucumber  mildew ' ,'Blight', 'Tomato Healthy',\n",
        " 'Leaf miners' ,'lettuce healthy'])\n",
        "ax.yaxis.set_ticklabels(['Cabbage  mildew' ,  'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " ' Cucumber  mildew ' ,'Blight', 'Tomato Healthy',\n",
        " 'Leaf miners' ,'lettuce healthy'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e_N324r45ey6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_names = ['True Neg','False Pos','False Neg','True Pos','True Pos','True Pos','True Pos','True Pos','True Pos']\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cm.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cm.flatten()/np.sum(cm)]\n",
        "labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
        "          zip(group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(8,8)\n",
        "ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Flower Category')\n",
        "ax.set_ylabel('Actual Flower Category ');\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Cabbage   diseases' , 'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " 'Cucumber diseases' ,'Tomato  diseases', 'Tomato Healthy',\n",
        " 'lettuce  diseases' ,'lettuce healthy'])\n",
        "ax.yaxis.set_ticklabels(['Cabbage   diseases' , 'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " 'Cucumber diseases' ,'Tomato  diseases', 'Tomato Healthy',\n",
        " 'lettuce  diseases' ,'lettuce healthy'])\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L0aVq_C6Qpuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "\n",
        "ax = sns.heatmap(cm/np.sum(cm), annot=True, \n",
        "            fmt='.2%', cmap='RdPu' , linewidths=.3)\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Cabbage   diseases' , 'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " 'Cucumber diseases' ,'Tomato  diseases', 'Tomato Healthy',\n",
        " 'lettuce  diseases' ,'lettuce healthy'])\n",
        "ax.yaxis.set_ticklabels(['Cabbage   diseases' , 'Cabbage Healthy' ,'Cucumber Healthy',\n",
        " 'Cucumber diseases' ,'Tomato  diseases', 'Tomato Healthy',\n",
        " 'lettuce  diseases' ,'lettuce healthy'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NFJ5RuR66n8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] Saving model...\")\n",
        "pickle.dump(model,open('cnn_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "W3zCB_6SFuyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "At5Zn5A2uCvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}